{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598739555376",
   "display_name": "Python 3.8.5 64-bit ('myproject': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"dim_reduction\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    #print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.utils import io\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    print('no prints in here')\n",
    "\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alone = 0\n",
    "Spontan = 1\n",
    "Sync = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets load the right hand solo,\n",
    "and we would actually from the get go merge it to the solo hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "HandRight = pd.read_csv(\"Unity Data\\HandRight.csv\")\n",
    "#HandRight.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indecies = [0,1,2] # notice we are droping hands count because this is cheating!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "HandRight = HandRight.drop(HandRight.columns[drop_indecies], axis=1)\n",
    "HandRight = HandRight.iloc[500:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      # hands   Position X   Position Y   Position Z   Velocity X  \\\n500         1     1.854658     163.3199     12.51509     67.33890   \n501         1     2.990307     163.0106     14.22045     63.82683   \n502         1     4.197042     162.9949     15.69018     69.52037   \n503         1     5.585192     163.3270     17.14896     81.45722   \n504         1     6.809369     163.0750     18.31746     64.54992   \n\n      Velocity Y   Velocity Z     Pitch      Roll       Yaw   Wrist Pos X  \\\n500     -6.28195    101.44220 -0.155174  0.078463 -0.764891      59.46534   \n501    -27.71448     91.91269 -0.166827  0.079468 -0.760001      60.39677   \n502     12.69234     67.46247 -0.172697  0.079392 -0.758363      61.55299   \n503     20.71213     85.95974 -0.162573  0.073489 -0.754197      62.87757   \n504    -20.25474     60.26554 -0.162684  0.071400 -0.747182      63.80330   \n\n      Wrist Pos Y   Wrist Pos Z   Elbow pos X   Elbow Pos Y   Elbow Pos Z  \\\n500      173.0233      60.61472      254.6348      127.2725      240.6239   \n501      173.5084      62.45371      257.0284      134.3396      242.4251   \n502      174.0561      63.92721      259.6933      142.5166      243.7431   \n503      173.9819      65.59348      262.3326      143.5807      244.1491   \n504      173.8077      67.11089      263.0048      144.4967      246.1332   \n\n      Grab Strenth   Grab Angle   Pinch Strength  \n500            0.0     0.401652              0.0  \n501            0.0     0.405177              0.0  \n502            0.0     0.378955              0.0  \n503            0.0     0.341598              0.0  \n504            0.0     0.299372              0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># hands</th>\n      <th>Position X</th>\n      <th>Position Y</th>\n      <th>Position Z</th>\n      <th>Velocity X</th>\n      <th>Velocity Y</th>\n      <th>Velocity Z</th>\n      <th>Pitch</th>\n      <th>Roll</th>\n      <th>Yaw</th>\n      <th>Wrist Pos X</th>\n      <th>Wrist Pos Y</th>\n      <th>Wrist Pos Z</th>\n      <th>Elbow pos X</th>\n      <th>Elbow Pos Y</th>\n      <th>Elbow Pos Z</th>\n      <th>Grab Strenth</th>\n      <th>Grab Angle</th>\n      <th>Pinch Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>500</th>\n      <td>1</td>\n      <td>1.854658</td>\n      <td>163.3199</td>\n      <td>12.51509</td>\n      <td>67.33890</td>\n      <td>-6.28195</td>\n      <td>101.44220</td>\n      <td>-0.155174</td>\n      <td>0.078463</td>\n      <td>-0.764891</td>\n      <td>59.46534</td>\n      <td>173.0233</td>\n      <td>60.61472</td>\n      <td>254.6348</td>\n      <td>127.2725</td>\n      <td>240.6239</td>\n      <td>0.0</td>\n      <td>0.401652</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>1</td>\n      <td>2.990307</td>\n      <td>163.0106</td>\n      <td>14.22045</td>\n      <td>63.82683</td>\n      <td>-27.71448</td>\n      <td>91.91269</td>\n      <td>-0.166827</td>\n      <td>0.079468</td>\n      <td>-0.760001</td>\n      <td>60.39677</td>\n      <td>173.5084</td>\n      <td>62.45371</td>\n      <td>257.0284</td>\n      <td>134.3396</td>\n      <td>242.4251</td>\n      <td>0.0</td>\n      <td>0.405177</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>1</td>\n      <td>4.197042</td>\n      <td>162.9949</td>\n      <td>15.69018</td>\n      <td>69.52037</td>\n      <td>12.69234</td>\n      <td>67.46247</td>\n      <td>-0.172697</td>\n      <td>0.079392</td>\n      <td>-0.758363</td>\n      <td>61.55299</td>\n      <td>174.0561</td>\n      <td>63.92721</td>\n      <td>259.6933</td>\n      <td>142.5166</td>\n      <td>243.7431</td>\n      <td>0.0</td>\n      <td>0.378955</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>1</td>\n      <td>5.585192</td>\n      <td>163.3270</td>\n      <td>17.14896</td>\n      <td>81.45722</td>\n      <td>20.71213</td>\n      <td>85.95974</td>\n      <td>-0.162573</td>\n      <td>0.073489</td>\n      <td>-0.754197</td>\n      <td>62.87757</td>\n      <td>173.9819</td>\n      <td>65.59348</td>\n      <td>262.3326</td>\n      <td>143.5807</td>\n      <td>244.1491</td>\n      <td>0.0</td>\n      <td>0.341598</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>1</td>\n      <td>6.809369</td>\n      <td>163.0750</td>\n      <td>18.31746</td>\n      <td>64.54992</td>\n      <td>-20.25474</td>\n      <td>60.26554</td>\n      <td>-0.162684</td>\n      <td>0.071400</td>\n      <td>-0.747182</td>\n      <td>63.80330</td>\n      <td>173.8077</td>\n      <td>67.11089</td>\n      <td>263.0048</td>\n      <td>144.4967</td>\n      <td>246.1332</td>\n      <td>0.0</td>\n      <td>0.299372</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "HandRight.head()\n",
    "#HandRight.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(875, 38)"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "k = pd.concat([HandRight.iloc[::4,:].reset_index(drop=True), HandRight.iloc[1::4,:].reset_index(drop=True)], axis=1)\n",
    "k.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HandRight.iloc[1:5*3+1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformData(df, type):\n",
    "    df = df.drop(df.columns[drop_indecies], axis=1)\n",
    "    if(type == Alone):\n",
    "        df = df.iloc[500:4000]\n",
    "        maxX = df.shape[0]\n",
    "        combine = np.hstack([HandRight[:maxX].values, df.values]).reshape(-1, df.shape[1])\n",
    "        df = pd.DataFrame(combine, columns=df.columns)\n",
    "    else:\n",
    "        df = df.iloc[1000:9000]\n",
    "        maxX = int(df.shape[0] / 2) * 2\n",
    "        df = df.iloc[:maxX]\n",
    "    df[df.columns[0]] -= 1\n",
    "    df.columns = df.columns.str.replace('#','')\n",
    "    df.columns = df.columns.str.lstrip()\n",
    "    df.columns = df.columns.str.rstrip()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df[\"state\"] = type\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, path):\n",
    "        li = []\n",
    "        all_files = glob.glob(path + \"/*\")\n",
    "        v = 0\n",
    "        for folder in all_files:\n",
    "            print(\"\\nloading in\" ,folder, ':')\n",
    "            files = glob.glob(folder + \"/*.csv\")\n",
    "            for filename in files:\n",
    "                df = pd.read_csv(filename, index_col=None, header=0)\n",
    "                type = None\n",
    "                if(\"Alone\" in filename):\n",
    "                    type = Alone\n",
    "                elif(\"Sync\" in filename):\n",
    "                    type = Sync\n",
    "                elif(\"Spontan\" in filename):\n",
    "                    type = Spontan\n",
    "                df = TransformData(df, type)\n",
    "                v += df.shape[0]\n",
    "                li.append(df)\n",
    "                print('loaded ', filename, type)\n",
    "        self.dataRaw = li\n",
    "        self.dataMerged = pd.concat(li, axis=0, sort=False)\n",
    "        print(self.dataMerged.shape, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nloading in Unity Data\\Training\\Evyatar Cohen :\nloaded  Unity Data\\Training\\Evyatar Cohen\\Evyatar636771052727603804Spontan.csv 1\nloaded  Unity Data\\Training\\Evyatar Cohen\\Evyatar636771053639929594Sync.csv 2\nloaded  Unity Data\\Training\\Evyatar Cohen\\Evyatar636771054555711409Alone.csv 0\n\nloading in Unity Data\\Training\\Nofar Social_Nuero :\nloaded  Unity Data\\Training\\Nofar Social_Nuero\\Nofar636759795182793299Spontan.csv 1\nloaded  Unity Data\\Training\\Nofar Social_Nuero\\Nofar636759796290435160Alone.csv 0\nloadedUnity Data\\Training\\Nofar Social_Nuero\\Nofar636759797397919664Sync.csv 2\n\nloading in Unity Data\\Training\\Oriya Social_Nuero :\nloaded  Unity Data\\Training\\Oriya Social_Nuero\\Oriya636759804404113837Spontan.csv 1\nloaded  Unity Data\\Training\\Oriya Social_Nuero\\Oriya636759805268396661Alone.csv 0\nloaded  Unity Data\\Training\\Oriya Social_Nuero\\Oriya636759806131350399Sync.csv 2\n\nloading in Unity Data\\Training\\Orya Kalmanovitz :\nloaded  Unity Data\\Training\\Orya Kalmanovitz\\OryaB636771082736601528Alone.csv 0\nloaded  Unity Data\\Training\\Orya Kalmanovitz\\OryaB636771083605535985Spontan.csv 1\nloaded  Unity Data\\Training\\Orya Kalmanovitz\\OryaB636771084494502229Sync.csv 2\n\nloading in Unity Data\\Training\\Revital Marbel :\nloaded Unity Data\\Training\\Revital Marbel\\Revital636770955999435879Alone.csv 0\nloaded  Unity Data\\Training\\Revital Marbel\\Revital636770957038873193Spontan.csv 1\nloaded  Unity Data\\Training\\Revital Marbel\\Revital636770957894370062Sync.csv 2\n\nloading in Unity Data\\Training\\Shahar Terner :\nloaded  Unity Data\\Training\\Shahar Terner\\Sachar636771045591258071Spontan.csv 1\nloaded  Unity Data\\Training\\Shahar Terner\\Sachar636771046527112972Sync.csv 2\nloaded  Unity Data\\Training\\Shahar Terner\\Sachar636771047408504303Alone.csv 0\n\nloading in Unity Data\\Training\\Shelly Social_Nuero :\nloaded  Unity Data\\Training\\Shelly Social_Nuero\\Shelly636759787508979097Spontan.csv 1\nloaded  Unity Data\\Training\\Shelly Social_Nuero\\Shelly636759788383205274Alone.csv 0\nloaded  Unity Data\\Training\\Shelly Social_Nuero\\Shelly636759789526313406Sync.csv 2\n\nloading in Unity Data\\Training\\Yael Hagai :\nloaded  Unity Data\\Training\\Yael Hagai\\Yael636771059544754823Spontan.csv 1\nloaded  Unity Data\\Training\\Yael Hagai\\Yael636771060699529085Sync.csv 2\nloaded  Unity Data\\Training\\Yael Hagai\\Yael636771061659067649Alone.csv 0\n\nloading in Unity Data\\Training\\Yoel Raz :\nloaded  Unity Data\\Training\\Yoel Raz\\Yoel636760921663075813Spontan.csv 1\nloaded  Unity Data\\Training\\Yoel Raz\\Yoel636760922573364655Alone.csv 0\nloaded  Unity Data\\Training\\Yoel Raz\\Yoel636760923490742912Sync.csv 2\n(193128, 20) 193128\n\nloading in Unity Data\\Validation\\Itiel Lab :\nloaded  Unity Data\\Validation\\Itiel Lab\\Itiel636770940701219076Spontan.csv 1\nloaded  Unity Data\\Validation\\Itiel Lab\\Itiel636770941638547912Sync.csv 2\nloaded  Unity Data\\Validation\\Itiel Lab\\Itiel636770942529041679Alone.csv 0\n\nloading in Unity Data\\Validation\\Mor SHerman :\nloaded  Unity Data\\Validation\\Mor SHerman\\Mor636771064635567065Spontan.csv 1\nloaded  Unity Data\\Validation\\Mor SHerman\\Mor636771065531910215Sync.csv 2\nloaded  Unity Data\\Validation\\Mor SHerman\\Mor636771066407626524Alone.csv 0\n\nloading in Unity Data\\Validation\\Oded Medina :\nloaded  Unity Data\\Validation\\Oded Medina\\Oded636754669540564461Alone.csv 0\nloaded  Unity Data\\Validation\\Oded Medina\\Oded636754670490266956Spontan.csv 1\nloaded  Unity Data\\Validation\\Oded Medina\\Oded636754671560850581Sync.csv 2\n(56210, 20) 56210\n"
    }
   ],
   "source": [
    "trainSet = DataLoader('Unity Data\\Training')\n",
    "testSet = DataLoader('Unity Data\\Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame\n",
    "data = trainSet.dataMerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataRaw is all the daraframes that we have already setup for us, now what we need is to generate from all of this,\n",
    "\n",
    "our actuall training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   hands  Velocity_X  Velocity_Y  Velocity_Z     Pitch      Roll       Yaw  \\\n0    0.0    67.33890    -6.28195  101.442200 -0.155174  0.078463 -0.764891   \n1    0.0    49.71883  -341.25160  -14.951780  1.199416  0.119953  1.519325   \n2    0.0    63.82683   -27.71448   91.912690 -0.166827  0.079468 -0.760001   \n3    0.0    36.02574  -309.41180    0.574942  1.089347  0.092826  1.515014   \n4    0.0    69.52037    12.69234   67.462470 -0.172697  0.079392 -0.758363   \n\n   Wrist_Pos_X  Wrist_Pos_Y  Wrist_Pos_Z  Elbow_pos_X  Elbow_Pos_Y  \\\n0     59.46534     173.0233     60.61472     254.6348    127.27250   \n1    -92.19111     218.0329     12.57041    -309.3688     85.11283   \n2     60.39677     173.5084     62.45371     257.0284    134.33960   \n3    -91.69262     214.4963     13.19102    -314.4200     89.30956   \n4     61.55299     174.0561     63.92721     259.6933    142.51660   \n\n   Elbow_Pos_Z  Grab_Strenth  Grab_Angle  Pinch_Strength  state  \n0    240.62390           0.0    0.401652             0.0      0  \n1    -24.33749           0.0    0.603028             0.0      0  \n2    242.42510           0.0    0.405177             0.0      0  \n3    -17.08960           0.0    0.313147             0.0      0  \n4    243.74310           0.0    0.378955             0.0      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hands</th>\n      <th>Velocity_X</th>\n      <th>Velocity_Y</th>\n      <th>Velocity_Z</th>\n      <th>Pitch</th>\n      <th>Roll</th>\n      <th>Yaw</th>\n      <th>Wrist_Pos_X</th>\n      <th>Wrist_Pos_Y</th>\n      <th>Wrist_Pos_Z</th>\n      <th>Elbow_pos_X</th>\n      <th>Elbow_Pos_Y</th>\n      <th>Elbow_Pos_Z</th>\n      <th>Grab_Strenth</th>\n      <th>Grab_Angle</th>\n      <th>Pinch_Strength</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>67.33890</td>\n      <td>-6.28195</td>\n      <td>101.442200</td>\n      <td>-0.155174</td>\n      <td>0.078463</td>\n      <td>-0.764891</td>\n      <td>59.46534</td>\n      <td>173.0233</td>\n      <td>60.61472</td>\n      <td>254.6348</td>\n      <td>127.27250</td>\n      <td>240.62390</td>\n      <td>0.0</td>\n      <td>0.401652</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>49.71883</td>\n      <td>-341.25160</td>\n      <td>-14.951780</td>\n      <td>1.199416</td>\n      <td>0.119953</td>\n      <td>1.519325</td>\n      <td>-92.19111</td>\n      <td>218.0329</td>\n      <td>12.57041</td>\n      <td>-309.3688</td>\n      <td>85.11283</td>\n      <td>-24.33749</td>\n      <td>0.0</td>\n      <td>0.603028</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>63.82683</td>\n      <td>-27.71448</td>\n      <td>91.912690</td>\n      <td>-0.166827</td>\n      <td>0.079468</td>\n      <td>-0.760001</td>\n      <td>60.39677</td>\n      <td>173.5084</td>\n      <td>62.45371</td>\n      <td>257.0284</td>\n      <td>134.33960</td>\n      <td>242.42510</td>\n      <td>0.0</td>\n      <td>0.405177</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>36.02574</td>\n      <td>-309.41180</td>\n      <td>0.574942</td>\n      <td>1.089347</td>\n      <td>0.092826</td>\n      <td>1.515014</td>\n      <td>-91.69262</td>\n      <td>214.4963</td>\n      <td>13.19102</td>\n      <td>-314.4200</td>\n      <td>89.30956</td>\n      <td>-17.08960</td>\n      <td>0.0</td>\n      <td>0.313147</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>69.52037</td>\n      <td>12.69234</td>\n      <td>67.462470</td>\n      <td>-0.172697</td>\n      <td>0.079392</td>\n      <td>-0.758363</td>\n      <td>61.55299</td>\n      <td>174.0561</td>\n      <td>63.92721</td>\n      <td>259.6933</td>\n      <td>142.51660</td>\n      <td>243.74310</td>\n      <td>0.0</td>\n      <td>0.378955</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Position_X  Position_Y  Position_Z  hands  Velocity_X  Velocity_Y  \\\n0       1.854658    163.3199    12.51509    0.0    67.33890    -6.28195   \n1     -20.808590    226.0860    17.08860    0.0    49.71883  -341.25160   \n2       2.990307    163.0106    14.22045    0.0    63.82683   -27.71448   \n3     -20.061710    220.5413    17.05443    0.0    36.02574  -309.41180   \n4       4.197042    162.9949    15.69018    0.0    69.52037    12.69234   \n...          ...         ...         ...    ...         ...         ...   \n6995  -73.616340    242.2852    69.19761    0.0  -188.33350   -50.49825   \n6996    3.230397    169.1729    -4.81981    0.0   224.79620  -538.24620   \n6997  -75.451450    242.0424    69.58482    0.0  -215.89570   -28.57200   \n6998    6.434268    161.4118   -12.09352    0.0   194.23230  -373.04310   \n6999  -77.681540    241.2202    70.17981    0.0  -104.96800   -32.57440   \n\n      Velocity_Z     Pitch      Roll       Yaw  Wrist_Pos_X  Wrist_Pos_Y  \\\n0     101.442200 -0.155174  0.078463 -0.764891     59.46534     173.0233   \n1     -14.951780  1.199416  0.119953  1.519325    -92.19111     218.0329   \n2      91.912690 -0.166827  0.079468 -0.760001     60.39677     173.5084   \n3       0.574942  1.089347  0.092826  1.515014    -91.69262     214.4963   \n4      67.462470 -0.172697  0.079392 -0.758363     61.55299     174.0561   \n...          ...       ...       ...       ...          ...          ...   \n6995   29.529870  1.857212  0.791704  1.893267   -119.80380     195.0393   \n6996 -463.401900  0.351476  0.213730 -0.117169     22.59152     148.0959   \n6997   45.553780  1.852507  0.801023  1.897196   -120.83340     194.0461   \n6998 -408.729000  0.309624  0.220371 -0.108358     25.10394     143.9342   \n6999   36.292190  1.832817  0.815892  1.893198   -121.49240     191.6418   \n\n      Wrist_Pos_Z  Elbow_pos_X  Elbow_Pos_Y  Elbow_Pos_Z  Grab_Strenth  \\\n0        60.61472     254.6348    127.27250    240.62390      0.000000   \n1        12.57041    -309.3688     85.11283    -24.33749      0.000000   \n2        62.45371     257.0284    134.33960    242.42510      0.000000   \n3        13.19102    -314.4200     89.30956    -17.08960      0.000000   \n4        63.92721     259.6933    142.51660    243.74310      0.000000   \n...           ...          ...          ...          ...           ...   \n6995     45.57323    -299.4263     41.95221    -32.44111      0.163370   \n6996     66.18939     158.3324     41.64271    276.20630      0.000000   \n6997     45.91526    -299.5178     40.43322    -33.21206      0.236677   \n6998     60.14394     156.3949     60.15020    282.87230      0.000000   \n6999     46.86401    -302.7603     42.34424    -34.61201      0.351044   \n\n      Grab_Angle  Pinch_Strength  state  \n0       0.401652        0.000000      0  \n1       0.603028        0.000000      0  \n2       0.405177        0.000000      0  \n3       0.313147        0.000000      0  \n4       0.378955        0.000000      0  \n...          ...             ...    ...  \n6995    1.244664        0.201331      0  \n6996    0.514317        0.000000      0  \n6997    1.400911        0.336688      0  \n6998    0.383218        0.000000      0  \n6999    1.702121        0.551523      0  \n\n[7000 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Position_X</th>\n      <th>Position_Y</th>\n      <th>Position_Z</th>\n      <th>hands</th>\n      <th>Velocity_X</th>\n      <th>Velocity_Y</th>\n      <th>Velocity_Z</th>\n      <th>Pitch</th>\n      <th>Roll</th>\n      <th>Yaw</th>\n      <th>Wrist_Pos_X</th>\n      <th>Wrist_Pos_Y</th>\n      <th>Wrist_Pos_Z</th>\n      <th>Elbow_pos_X</th>\n      <th>Elbow_Pos_Y</th>\n      <th>Elbow_Pos_Z</th>\n      <th>Grab_Strenth</th>\n      <th>Grab_Angle</th>\n      <th>Pinch_Strength</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.854658</td>\n      <td>163.3199</td>\n      <td>12.51509</td>\n      <td>0.0</td>\n      <td>67.33890</td>\n      <td>-6.28195</td>\n      <td>101.442200</td>\n      <td>-0.155174</td>\n      <td>0.078463</td>\n      <td>-0.764891</td>\n      <td>59.46534</td>\n      <td>173.0233</td>\n      <td>60.61472</td>\n      <td>254.6348</td>\n      <td>127.27250</td>\n      <td>240.62390</td>\n      <td>0.000000</td>\n      <td>0.401652</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-20.808590</td>\n      <td>226.0860</td>\n      <td>17.08860</td>\n      <td>0.0</td>\n      <td>49.71883</td>\n      <td>-341.25160</td>\n      <td>-14.951780</td>\n      <td>1.199416</td>\n      <td>0.119953</td>\n      <td>1.519325</td>\n      <td>-92.19111</td>\n      <td>218.0329</td>\n      <td>12.57041</td>\n      <td>-309.3688</td>\n      <td>85.11283</td>\n      <td>-24.33749</td>\n      <td>0.000000</td>\n      <td>0.603028</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.990307</td>\n      <td>163.0106</td>\n      <td>14.22045</td>\n      <td>0.0</td>\n      <td>63.82683</td>\n      <td>-27.71448</td>\n      <td>91.912690</td>\n      <td>-0.166827</td>\n      <td>0.079468</td>\n      <td>-0.760001</td>\n      <td>60.39677</td>\n      <td>173.5084</td>\n      <td>62.45371</td>\n      <td>257.0284</td>\n      <td>134.33960</td>\n      <td>242.42510</td>\n      <td>0.000000</td>\n      <td>0.405177</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-20.061710</td>\n      <td>220.5413</td>\n      <td>17.05443</td>\n      <td>0.0</td>\n      <td>36.02574</td>\n      <td>-309.41180</td>\n      <td>0.574942</td>\n      <td>1.089347</td>\n      <td>0.092826</td>\n      <td>1.515014</td>\n      <td>-91.69262</td>\n      <td>214.4963</td>\n      <td>13.19102</td>\n      <td>-314.4200</td>\n      <td>89.30956</td>\n      <td>-17.08960</td>\n      <td>0.000000</td>\n      <td>0.313147</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.197042</td>\n      <td>162.9949</td>\n      <td>15.69018</td>\n      <td>0.0</td>\n      <td>69.52037</td>\n      <td>12.69234</td>\n      <td>67.462470</td>\n      <td>-0.172697</td>\n      <td>0.079392</td>\n      <td>-0.758363</td>\n      <td>61.55299</td>\n      <td>174.0561</td>\n      <td>63.92721</td>\n      <td>259.6933</td>\n      <td>142.51660</td>\n      <td>243.74310</td>\n      <td>0.000000</td>\n      <td>0.378955</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6995</th>\n      <td>-73.616340</td>\n      <td>242.2852</td>\n      <td>69.19761</td>\n      <td>0.0</td>\n      <td>-188.33350</td>\n      <td>-50.49825</td>\n      <td>29.529870</td>\n      <td>1.857212</td>\n      <td>0.791704</td>\n      <td>1.893267</td>\n      <td>-119.80380</td>\n      <td>195.0393</td>\n      <td>45.57323</td>\n      <td>-299.4263</td>\n      <td>41.95221</td>\n      <td>-32.44111</td>\n      <td>0.163370</td>\n      <td>1.244664</td>\n      <td>0.201331</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6996</th>\n      <td>3.230397</td>\n      <td>169.1729</td>\n      <td>-4.81981</td>\n      <td>0.0</td>\n      <td>224.79620</td>\n      <td>-538.24620</td>\n      <td>-463.401900</td>\n      <td>0.351476</td>\n      <td>0.213730</td>\n      <td>-0.117169</td>\n      <td>22.59152</td>\n      <td>148.0959</td>\n      <td>66.18939</td>\n      <td>158.3324</td>\n      <td>41.64271</td>\n      <td>276.20630</td>\n      <td>0.000000</td>\n      <td>0.514317</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6997</th>\n      <td>-75.451450</td>\n      <td>242.0424</td>\n      <td>69.58482</td>\n      <td>0.0</td>\n      <td>-215.89570</td>\n      <td>-28.57200</td>\n      <td>45.553780</td>\n      <td>1.852507</td>\n      <td>0.801023</td>\n      <td>1.897196</td>\n      <td>-120.83340</td>\n      <td>194.0461</td>\n      <td>45.91526</td>\n      <td>-299.5178</td>\n      <td>40.43322</td>\n      <td>-33.21206</td>\n      <td>0.236677</td>\n      <td>1.400911</td>\n      <td>0.336688</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6998</th>\n      <td>6.434268</td>\n      <td>161.4118</td>\n      <td>-12.09352</td>\n      <td>0.0</td>\n      <td>194.23230</td>\n      <td>-373.04310</td>\n      <td>-408.729000</td>\n      <td>0.309624</td>\n      <td>0.220371</td>\n      <td>-0.108358</td>\n      <td>25.10394</td>\n      <td>143.9342</td>\n      <td>60.14394</td>\n      <td>156.3949</td>\n      <td>60.15020</td>\n      <td>282.87230</td>\n      <td>0.000000</td>\n      <td>0.383218</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6999</th>\n      <td>-77.681540</td>\n      <td>241.2202</td>\n      <td>70.17981</td>\n      <td>0.0</td>\n      <td>-104.96800</td>\n      <td>-32.57440</td>\n      <td>36.292190</td>\n      <td>1.832817</td>\n      <td>0.815892</td>\n      <td>1.893198</td>\n      <td>-121.49240</td>\n      <td>191.6418</td>\n      <td>46.86401</td>\n      <td>-302.7603</td>\n      <td>42.34424</td>\n      <td>-34.61201</td>\n      <td>0.351044</td>\n      <td>1.702121</td>\n      <td>0.551523</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7000 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "k = trainSet.dataRaw[4]\n",
    "w = k.iloc[:,[1,2,3]]\n",
    "k = k.drop(k.columns[[1,2,3]], axis=1)\n",
    "k.head()\n",
    "k = pd.concat([w.reset_index(drop=True), k.reset_index(drop=True)], axis=1)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate our np_array so first of all lets create a new class,\n",
    "\n",
    "class would do the following it would get a settings : colloums it should drop, \n",
    "\n",
    "(jumps in time, and number of frames per row, andoverall jumps on the dataset),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Pitch'], dtype='object')"
     },
     "metadata": {},
     "execution_count": 74
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Pitch\n0 -0.155174\n5  0.913572",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pitch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.155174</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.913572</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Pitch\n1  1.199416\n6 -0.162573",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pitch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.199416</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.162573</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Pitch\n0  0.522121\n1  0.375499",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pitch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.522121</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.375499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# k = training.dataRaw[4].iloc[1:2*2+1:2,:].to_numpy()\n",
    "# w = training.dataRaw[4].iloc[:2*2:2,:].to_numpy()\n",
    "# k\n",
    "# w\n",
    "\n",
    "# np.concatenate((k, w), axis=0)\n",
    "\n",
    "#training.dataRaw[4]['state'][0]\n",
    "\n",
    "w1 =  trainSet.dataRaw[4].iloc[::5,[7]][:2]\n",
    "w2 = trainSet.dataRaw[4].iloc[1::5,[7]][:2]\n",
    "\n",
    "w1.columns\n",
    "w1\n",
    "w2\n",
    "w3 = pd.concat([w1.reset_index(drop=True), w2.reset_index(drop=True)], axis = 1)\n",
    "w3.groupby(lambda x:x, axis=1).mean()\n",
    "\n",
    "#training.dataRaw[4].drop('state', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataToNP:\n",
    "    def __init__(self, label_index, jumps, combine = 4, skips = 1, drop_indecies = [], merge_indecies = [], merge_seperate = []):\n",
    "        self.drop_indecies = drop_indecies\n",
    "        self.label_index = label_index\n",
    "        self.jumps = jumps\n",
    "        self.combine = combine\n",
    "        self.merge_indecies = merge_indecies\n",
    "        self.merge_seperate = merge_seperate\n",
    "        if(skips < 0):\n",
    "            skips = skips % self.jumps\n",
    "        self.skips = skips\n",
    "\n",
    "    def transform(self, data, skips = -1):\n",
    "        if(skips < 0):\n",
    "            skips = self.skips\n",
    "        state = data[self.label_index].iloc[0]\n",
    "        if(len(self.drop_indecies) > 0):\n",
    "            current = data.drop(data.columns[self.drop_indecies], axis=1)\n",
    "            current = current.drop(self.label_index, axis=1)\n",
    "        else:\n",
    "            current = data.drop(self.label_index, axis=1)\n",
    "        \n",
    "\n",
    "        mi = data.iloc[:, self.merge_indecies]\n",
    "        msi = data.iloc[:, self.merge_seperate]\n",
    "        mi = pd.concat([mi.iloc[::2,:].reset_index(drop=True), mi.iloc[1::2,:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "        msi1 = msi.iloc[::2,:].reset_index(drop=True)\n",
    "        msi2 = msi.iloc[1::2,:].reset_index(drop=True)\n",
    "\n",
    "        msi1.columns += \"_r\"\n",
    "        msi2.columns += \"_l\"\n",
    "\n",
    "        _drop = list(self.merge_indecies) + list(self.merge_seperate)\n",
    "        current = current.drop(data.columns[_drop], axis=1)\n",
    "\n",
    "        current_r = current.iloc[::2,:].reset_index(drop=True)\n",
    "        current_l = current.iloc[1::2,:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        current_r.columns = current_r.columns + \"_r\"\n",
    "        current_l.columns = current_l.columns + \"_l\"\n",
    "        current = pd.concat([current_r, current_l], axis=1)\n",
    "        li = []\n",
    "        if(skips < 1):\n",
    "            skips = 1\n",
    "        for i in range(0, self.jumps, skips):\n",
    "            df = current.iloc[i::self.jumps,:]\n",
    "            comb = []\n",
    "            mis = []\n",
    "\n",
    "            msis1 = []\n",
    "            msis2 = []\n",
    "            for j in range(self.combine):\n",
    "                sample = df.iloc[j::self.combine]\n",
    "                comb.append(sample.reset_index(drop=True))\n",
    "\n",
    "                mi_sample = mi.iloc[i::self.jumps,:].iloc[j::self.combine]\n",
    "                mis.append(mi_sample.reset_index(drop=True))\n",
    "\n",
    "                msi_sample1 = msi1.iloc[i::self.jumps,:].iloc[j::self.combine]\n",
    "                msi_sample2 = msi2.iloc[i::self.jumps,:].iloc[j::self.combine]\n",
    "                       \n",
    "                msis1.append(msi_sample1.reset_index(drop=True))\n",
    "                msis2.append(msi_sample2.reset_index(drop=True))\n",
    "            \n",
    "            vmi = pd.concat(mis, axis=1).groupby(lambda x:x, axis=1).mean()\n",
    "            vmsi1 = pd.concat(msis1, axis=1).groupby(lambda x:x, axis=1).mean()\n",
    "            vmsi2 = pd.concat(msis2, axis=1).groupby(lambda x:x, axis=1).mean()\n",
    "\n",
    "            vmsi = pd.concat([vmsi1.reset_index(drop=True), vmsi2.reset_index(drop=True)], axis=1)\n",
    "            #comb.append(mi.iloc[i::self.jumps,:][::self.combine].reset_index(drop=True))\n",
    "            comb.append(vmi)\n",
    "            comb.append(vmsi)\n",
    "            df = pd.concat(comb, axis=1)\n",
    "            #df['state'] = type\n",
    "            li.append(df.dropna())\n",
    "        df = pd.concat(li, axis=0, sort=False) \n",
    "        df['state'] = state     \n",
    "        return df\n",
    "    \n",
    "    def transform_arr(self, df_arr, skips = -1):\n",
    "        arr = []\n",
    "        print(\"combining\", len(df_arr), \"dataframes\")\n",
    "        for df in df_arr:\n",
    "            arr.append(self.transform(df, skips))\n",
    "            #X = np.concatenate((X, t[0]), axis=0)\n",
    "            #y = np.concatenate((y, t[1]), axis=0)\n",
    "        return arr\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test seeing that the class actually works!\n",
    "\n",
    "it does so cool,\n",
    "\n",
    "we want to combine every 2 rows ( right and left hand), then we want,\n",
    "\n",
    "to sample with jumps ( here its 2 ), and we will combine every 2 jumps.\n",
    "\n",
    "also if we got a line that has missing properties a.k.a we combined a line with a non existent one,\n",
    "\n",
    "we will drop that line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Name  Age  label\n0     1   20      1\n1     2   21      1\n2     3   19      1\n3     4   18      1\n4     5   20      1\n5     6   21      1\n6     7   19      1\n7     8   18      1\n8     9   17      1\n9    10   16      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Name_r  Age_r  Name_l  Age_l  Name_r  Age_r  Name_l  Age_l  state\n0       1     20       2     21     5.0   20.0     6.0   21.0      1\n0       3     19       4     18     7.0   19.0     8.0   18.0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name_r</th>\n      <th>Age_r</th>\n      <th>Name_l</th>\n      <th>Age_l</th>\n      <th>Name_r</th>\n      <th>Age_r</th>\n      <th>Name_l</th>\n      <th>Age_l</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>21</td>\n      <td>5.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>19</td>\n      <td>4</td>\n      <td>18</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>8.0</td>\n      <td>18.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "combining 2 dataframes\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[   Name_r  Age_r  Name_l  Age_l  Name_r  Age_r  Name_l  Age_l  state\n 0       1     20       2     21     5.0   20.0     6.0   21.0      1\n 0       3     19       4     18     7.0   19.0     8.0   18.0      1,\n    Name_r  Age_r  Name_l  Age_l  Name_r  Age_r  Name_l  Age_l  state\n 0      11     20      22     21    55.0   20.0    66.0   21.0      2\n 0      33     19      44     18    77.0   19.0    88.0   18.0      2]"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "test_data = {'Name':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'Age':[20, 21, 19, 18, 20, 21, 19, 18, 17, 16],\n",
    "        'label':[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "test_data2 = {'Name':[11, 22, 33, 44, 55, 66, 77, 88, 99, 1010],\n",
    "        'Age':[20, 21, 19, 18, 20, 21, 19, 18, 17, 16],\n",
    "        'label':[2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n",
    " \n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df2 = pd.DataFrame(test_data2)\n",
    "li = [test_df, test_df2]\n",
    "\n",
    "# Create DataFrame\n",
    "\n",
    "test_df\n",
    "combinerTest = DataToNP('label', 2, combine=2)\n",
    "combinerTest.transform(test_df)\n",
    "\n",
    "combinerTest.transform_arr(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what is the corroletion to the state variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3\n",
    "\n",
    "def between(corr, min, max):\n",
    "    first = (abs(corr[\"state\"]) > min)\n",
    "    second = (abs(corr[\"state\"]) < max)\n",
    "    first = [i for i, x in enumerate(first) if x]\n",
    "    second = [i for i, x in enumerate(second) if x]\n",
    "    return intersection(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Elbow_Pos_Z      -0.399522\nElbow_Pos_Y      -0.252712\nGrab_Angle       -0.219273\nYaw              -0.162749\nWrist_Pos_Z      -0.137829\nPinch_Strength   -0.137151\nGrab_Strenth     -0.080044\nWrist_Pos_Y      -0.058052\nRoll             -0.023557\nVelocity_X       -0.007780\nVelocity_Z        0.003729\nVelocity_Y        0.008675\nPosition_Z        0.047028\nPosition_X        0.077259\nPosition_Y        0.089554\nElbow_pos_X       0.108218\nWrist_Pos_X       0.110207\nPitch             0.257066\nhands             0.830492\nstate             1.000000\nName: state, dtype: float64"
     },
     "metadata": {},
     "execution_count": 78
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['hands', 'Position_X', 'Position_Y', 'Position_Z', 'Velocity_X',\n       'Velocity_Y', 'Velocity_Z', 'Pitch', 'Roll', 'Yaw', 'Wrist_Pos_X',\n       'Wrist_Pos_Y', 'Wrist_Pos_Z', 'Elbow_pos_X', 'Elbow_Pos_Y',\n       'Elbow_Pos_Z', 'Grab_Strenth', 'Grab_Angle', 'Pinch_Strength', 'state'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 78
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nremove : \n Index(['Position_Z', 'Velocity_X', 'Velocity_Z', 'Roll'], dtype='object')\n\n\nmerged : \n Index(['hands', 'Velocity_Y', 'Pitch', 'Elbow_Pos_Y', 'Elbow_Pos_Z',\n       'Grab_Angle'],\n      dtype='object')\n\n\nmerged with RL : \n Index(['Position_X', 'Position_Y', 'Yaw', 'Wrist_Pos_X', 'Wrist_Pos_Y',\n       'Wrist_Pos_Z', 'Elbow_pos_X', 'Grab_Strenth', 'Pinch_Strength'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "corr_matrix = trainSet.dataMerged.corr()\n",
    "corr_matrix[\"state\"].sort_values()\n",
    "\n",
    "import math\n",
    "delete_arr_f = (abs(corr_matrix[\"state\"]) <= 0.05)\n",
    "delete_arr_f = [i for i, x in enumerate(delete_arr_f) if x]\n",
    "delete_arr_f.remove(5)\n",
    "\n",
    "merge_seperate = between(corr_matrix, 0.05, 0.2)\n",
    "\n",
    "#merge_seperate.remove(0)\n",
    "\n",
    "trainSet.dataMerged.columns\n",
    "\n",
    "merge = list(range(0, trainSet.dataMerged.shape[1] - 1))\n",
    "save = []\n",
    "\n",
    "#trainSet.dataMerged.columns[merge_seperate]\n",
    "#trainSet.dataMerged.columns[drop_i]\n",
    "\n",
    "merge = np.setdiff1d(merge, merge_seperate)\n",
    "merge = np.setdiff1d(merge, save)\n",
    "merge = np.setdiff1d(merge, delete_arr_f)\n",
    "\n",
    "print(\"\\nremove : \\n\",  trainSet.dataMerged.columns[delete_arr_f])\n",
    "print(\"\\n\\nmerged : \\n\",  trainSet.dataMerged.columns[merge])\n",
    "print(\"\\n\\nmerged with RL : \\n\",  trainSet.dataMerged.columns[merge_seperate])\n",
    "#print(merge, merge_seperate, delete_arr_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove positions, velocities, and roll and wrist pos Y, and grabStrength,\n",
    "\n",
    "they give to little effect and would probably hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Elbow_Pos_Y  Elbow_Pos_Z  Grab_Angle     Pitch  Velocity_Y  hands  \\\n0     39.823218     8.821516    0.558606  1.951806   -9.772053    0.6   \n1     42.504997    70.235662    0.620478  1.401055  -24.130205    1.0   \n2     47.573770    63.465303    1.211767  1.654547   13.360834    1.0   \n3     51.279769    71.299116    1.354158  0.926535   20.784507    1.0   \n4     48.321454    85.919137    0.707550  0.772073  -15.139557    1.0   \n..          ...          ...         ...       ...         ...    ...   \n35    55.999232    96.102148    0.963165  0.823711  -67.256190    1.0   \n36    19.082920    76.799393    1.216995  1.454497   63.846141    1.0   \n37   -13.134776    45.806365    1.032783  1.251151   16.944638    1.0   \n38    -2.426512    57.593913    1.131793  1.404055   48.849163    1.0   \n39    14.129262    98.891480    1.639229  1.172521  -29.454765    1.0   \n\n    Elbow_pos_X_r  Grab_Strenth_r  Pinch_Strength_r  Position_X_r  ...  \\\n0       47.492740        0.000000          0.051396     20.320220  ...   \n1     -363.819520        0.000000          0.177196   -148.724740  ...   \n2     -385.832580        0.552808          0.682555   -145.205740  ...   \n3     -380.944940        0.200000          0.586907   -150.382880  ...   \n4     -380.750100        0.093348          0.276380   -163.980380  ...   \n..            ...             ...               ...           ...  ...   \n35    -359.389480        0.400000          0.260173    -80.093830  ...   \n36    -370.458800        0.385013          0.481766    -83.081300  ...   \n37    -359.675760        0.200000          0.373226    -92.883898  ...   \n38    -350.172140        0.310415          0.451635    -95.276534  ...   \n39    -392.173575        0.863503          0.760877   -108.756438  ...   \n\n    Elbow_pos_X_l  Grab_Strenth_l  Pinch_Strength_l  Position_X_l  \\\n0     -349.700680        0.000000          0.252371   -164.143060   \n1      360.315440        0.035093          0.000000    171.782640   \n2      379.277820        0.000000          0.000000    168.240520   \n3      387.781200        0.195183          0.000000    176.754660   \n4      338.547940        0.000000          0.000000    133.113600   \n..            ...             ...               ...           ...   \n35     391.543060        0.000000          0.000000    138.083800   \n36     362.558720        0.167032          0.000000    149.230240   \n37     335.888720        0.038420          0.000000    146.824220   \n38     343.700480        0.000000          0.000000    160.676680   \n39     346.884375        0.012242          0.000000    163.979625   \n\n    Position_Y_l  Wrist_Pos_X_l  Wrist_Pos_Y_l  Wrist_Pos_Z_l     Yaw_l  state  \n0     254.764200    -209.794440     222.678120      24.159870  2.246202      1  \n1     247.259560     206.349480     193.630740      82.827944 -0.637905      1  \n2     245.700880     211.307960     194.363520      82.502964 -0.861536      1  \n3     250.525160     213.734560     200.235760      96.436426 -0.574027      1  \n4     218.211660     172.939080     180.457340      93.681730 -0.560945      1  \n..           ...            ...            ...            ...       ...    ...  \n35    195.102840     185.969340     149.850020     116.670180 -1.209123      1  \n36    217.958280     192.978400     160.187960      94.994286 -1.456968      1  \n37    213.155840     191.488220     156.176920      79.009750 -1.469253      1  \n38    230.442380     201.862680     171.227240      80.999386 -1.396328      1  \n39    215.074075     205.807975     163.096675      52.519290 -0.867346      1  \n\n[800 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Elbow_Pos_Y</th>\n      <th>Elbow_Pos_Z</th>\n      <th>Grab_Angle</th>\n      <th>Pitch</th>\n      <th>Velocity_Y</th>\n      <th>hands</th>\n      <th>Elbow_pos_X_r</th>\n      <th>Grab_Strenth_r</th>\n      <th>Pinch_Strength_r</th>\n      <th>Position_X_r</th>\n      <th>...</th>\n      <th>Elbow_pos_X_l</th>\n      <th>Grab_Strenth_l</th>\n      <th>Pinch_Strength_l</th>\n      <th>Position_X_l</th>\n      <th>Position_Y_l</th>\n      <th>Wrist_Pos_X_l</th>\n      <th>Wrist_Pos_Y_l</th>\n      <th>Wrist_Pos_Z_l</th>\n      <th>Yaw_l</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39.823218</td>\n      <td>8.821516</td>\n      <td>0.558606</td>\n      <td>1.951806</td>\n      <td>-9.772053</td>\n      <td>0.6</td>\n      <td>47.492740</td>\n      <td>0.000000</td>\n      <td>0.051396</td>\n      <td>20.320220</td>\n      <td>...</td>\n      <td>-349.700680</td>\n      <td>0.000000</td>\n      <td>0.252371</td>\n      <td>-164.143060</td>\n      <td>254.764200</td>\n      <td>-209.794440</td>\n      <td>222.678120</td>\n      <td>24.159870</td>\n      <td>2.246202</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42.504997</td>\n      <td>70.235662</td>\n      <td>0.620478</td>\n      <td>1.401055</td>\n      <td>-24.130205</td>\n      <td>1.0</td>\n      <td>-363.819520</td>\n      <td>0.000000</td>\n      <td>0.177196</td>\n      <td>-148.724740</td>\n      <td>...</td>\n      <td>360.315440</td>\n      <td>0.035093</td>\n      <td>0.000000</td>\n      <td>171.782640</td>\n      <td>247.259560</td>\n      <td>206.349480</td>\n      <td>193.630740</td>\n      <td>82.827944</td>\n      <td>-0.637905</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47.573770</td>\n      <td>63.465303</td>\n      <td>1.211767</td>\n      <td>1.654547</td>\n      <td>13.360834</td>\n      <td>1.0</td>\n      <td>-385.832580</td>\n      <td>0.552808</td>\n      <td>0.682555</td>\n      <td>-145.205740</td>\n      <td>...</td>\n      <td>379.277820</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>168.240520</td>\n      <td>245.700880</td>\n      <td>211.307960</td>\n      <td>194.363520</td>\n      <td>82.502964</td>\n      <td>-0.861536</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51.279769</td>\n      <td>71.299116</td>\n      <td>1.354158</td>\n      <td>0.926535</td>\n      <td>20.784507</td>\n      <td>1.0</td>\n      <td>-380.944940</td>\n      <td>0.200000</td>\n      <td>0.586907</td>\n      <td>-150.382880</td>\n      <td>...</td>\n      <td>387.781200</td>\n      <td>0.195183</td>\n      <td>0.000000</td>\n      <td>176.754660</td>\n      <td>250.525160</td>\n      <td>213.734560</td>\n      <td>200.235760</td>\n      <td>96.436426</td>\n      <td>-0.574027</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.321454</td>\n      <td>85.919137</td>\n      <td>0.707550</td>\n      <td>0.772073</td>\n      <td>-15.139557</td>\n      <td>1.0</td>\n      <td>-380.750100</td>\n      <td>0.093348</td>\n      <td>0.276380</td>\n      <td>-163.980380</td>\n      <td>...</td>\n      <td>338.547940</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>133.113600</td>\n      <td>218.211660</td>\n      <td>172.939080</td>\n      <td>180.457340</td>\n      <td>93.681730</td>\n      <td>-0.560945</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>55.999232</td>\n      <td>96.102148</td>\n      <td>0.963165</td>\n      <td>0.823711</td>\n      <td>-67.256190</td>\n      <td>1.0</td>\n      <td>-359.389480</td>\n      <td>0.400000</td>\n      <td>0.260173</td>\n      <td>-80.093830</td>\n      <td>...</td>\n      <td>391.543060</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>138.083800</td>\n      <td>195.102840</td>\n      <td>185.969340</td>\n      <td>149.850020</td>\n      <td>116.670180</td>\n      <td>-1.209123</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>19.082920</td>\n      <td>76.799393</td>\n      <td>1.216995</td>\n      <td>1.454497</td>\n      <td>63.846141</td>\n      <td>1.0</td>\n      <td>-370.458800</td>\n      <td>0.385013</td>\n      <td>0.481766</td>\n      <td>-83.081300</td>\n      <td>...</td>\n      <td>362.558720</td>\n      <td>0.167032</td>\n      <td>0.000000</td>\n      <td>149.230240</td>\n      <td>217.958280</td>\n      <td>192.978400</td>\n      <td>160.187960</td>\n      <td>94.994286</td>\n      <td>-1.456968</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>-13.134776</td>\n      <td>45.806365</td>\n      <td>1.032783</td>\n      <td>1.251151</td>\n      <td>16.944638</td>\n      <td>1.0</td>\n      <td>-359.675760</td>\n      <td>0.200000</td>\n      <td>0.373226</td>\n      <td>-92.883898</td>\n      <td>...</td>\n      <td>335.888720</td>\n      <td>0.038420</td>\n      <td>0.000000</td>\n      <td>146.824220</td>\n      <td>213.155840</td>\n      <td>191.488220</td>\n      <td>156.176920</td>\n      <td>79.009750</td>\n      <td>-1.469253</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>-2.426512</td>\n      <td>57.593913</td>\n      <td>1.131793</td>\n      <td>1.404055</td>\n      <td>48.849163</td>\n      <td>1.0</td>\n      <td>-350.172140</td>\n      <td>0.310415</td>\n      <td>0.451635</td>\n      <td>-95.276534</td>\n      <td>...</td>\n      <td>343.700480</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>160.676680</td>\n      <td>230.442380</td>\n      <td>201.862680</td>\n      <td>171.227240</td>\n      <td>80.999386</td>\n      <td>-1.396328</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>14.129262</td>\n      <td>98.891480</td>\n      <td>1.639229</td>\n      <td>1.172521</td>\n      <td>-29.454765</td>\n      <td>1.0</td>\n      <td>-392.173575</td>\n      <td>0.863503</td>\n      <td>0.760877</td>\n      <td>-108.756438</td>\n      <td>...</td>\n      <td>346.884375</td>\n      <td>0.012242</td>\n      <td>0.000000</td>\n      <td>163.979625</td>\n      <td>215.074075</td>\n      <td>205.807975</td>\n      <td>163.096675</td>\n      <td>52.519290</td>\n      <td>-0.867346</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "jumps = 20\n",
    "combine = 5\n",
    "skip = 1\n",
    "label = 'state'\n",
    "\n",
    "features =  trainSet.dataMerged.shape[1]\n",
    "# MyCombiner = DataToNP(label_index = label, skips=skip, jumps=jumps, combine=combine, \n",
    "#     drop_indecies=[], merge_indecies = [0,16,17,18])\n",
    "\n",
    "MyCombiner = DataToNP(label_index = label, skips=skip, jumps=jumps, combine=combine, \n",
    "    drop_indecies = delete_arr_f, merge_indecies = merge, merge_seperate = merge_seperate)\n",
    "\n",
    "# test if we get the same dementions its working\n",
    "\n",
    "# MyCombiner.transform(training.dataRaw[4]).shape\n",
    "# (training.dataRaw[4].shape[1] - 1) * combine * 2\n",
    "# rows_afterJoining = (training.dataRaw[4].shape[0]/2) \n",
    "# import math\n",
    "# int(int(int(rows_afterJoining/jumps )/combine) * math.ceil(jumps / skip))\n",
    "\n",
    "w = MyCombiner.transform(trainSet.dataRaw[3])\n",
    "w\n",
    "\n",
    "#training.dataRaw[3].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loots good so the combiner works as expected!\n",
    "\n",
    "there should be no problems with multiple dataFrames as it just doing the same function and combining the end result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "combining 27 dataframes\ncombining 9 dataframes\n"
    }
   ],
   "source": [
    "train_df = MyCombiner.transform_arr(trainSet.dataRaw)\n",
    "test_df = MyCombiner.transform_arr(testSet.dataRaw)\n",
    "train_merged = pd.concat(train_df, axis=0, sort=False) \n",
    "test_merged = pd.concat(test_df, axis=0, sort=False) \n",
    "#X_train_df[0]\n",
    "#MyCombiner.transform(training.dataRaw[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(19367, 25)"
     },
     "metadata": {},
     "execution_count": 81
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5680, 25)"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "train_merged.shape\n",
    "test_merged.shape\n",
    "\n",
    "m = train_merged.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Elbow_Pos_Z        -0.737063\nWrist_Pos_Z_r      -0.454723\nElbow_Pos_Y        -0.422112\nGrab_Angle         -0.392061\nPinch_Strength_l   -0.267390\nYaw_l              -0.240990\nGrab_Strenth_l     -0.192406\nWrist_Pos_Y_l      -0.150854\nYaw_r              -0.133663\nPinch_Strength_r   -0.102741\nGrab_Strenth_r     -0.058546\nElbow_pos_X_r      -0.032033\nWrist_Pos_Y_r      -0.004474\nPosition_X_r        0.035015\nWrist_Pos_X_r       0.035316\nVelocity_Y          0.038036\nPosition_Y_l        0.065449\nWrist_Pos_Z_l       0.109200\nPosition_X_l        0.138378\nWrist_Pos_X_l       0.209902\nPosition_Y_r        0.219273\nElbow_pos_X_l       0.267262\nPitch               0.473682\nhands               0.845177\nstate               1.000000\nName: state, dtype: float64"
     },
     "metadata": {},
     "execution_count": 82
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Elbow_Pos_Z        -0.666839\nGrab_Angle         -0.495884\nElbow_Pos_Y        -0.460887\nPinch_Strength_l   -0.434554\nWrist_Pos_Z_r      -0.432349\nYaw_l              -0.419605\nGrab_Strenth_l     -0.388303\nWrist_Pos_Y_l      -0.364634\nPosition_Y_l       -0.198770\nPinch_Strength_r   -0.117654\nYaw_r              -0.110416\nElbow_pos_X_r      -0.075414\nWrist_Pos_Z_l      -0.057360\nGrab_Strenth_r     -0.056759\nWrist_Pos_Y_r      -0.045704\nWrist_Pos_X_r       0.025776\nPosition_X_l        0.030806\nPosition_X_r        0.037284\nVelocity_Y          0.058195\nWrist_Pos_X_l       0.148226\nPosition_Y_r        0.197893\nElbow_pos_X_l       0.262397\nPitch               0.510126\nhands               0.841148\nstate               1.000000\nName: state, dtype: float64"
     },
     "metadata": {},
     "execution_count": 82
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Elbow_Pos_Y        -0.038775\nElbow_Pos_Z         0.070224\nGrab_Angle         -0.103822\nPitch               0.036445\nVelocity_Y          0.020159\nhands              -0.004028\nElbow_pos_X_r      -0.043381\nGrab_Strenth_r      0.001786\nPinch_Strength_r   -0.014913\nPosition_X_r        0.002270\nPosition_Y_r       -0.021381\nWrist_Pos_X_r      -0.009539\nWrist_Pos_Y_r      -0.041230\nWrist_Pos_Z_r       0.022374\nYaw_r               0.023247\nElbow_pos_X_l      -0.004865\nGrab_Strenth_l     -0.195897\nPinch_Strength_l   -0.167164\nPosition_X_l       -0.107572\nPosition_Y_l       -0.264219\nWrist_Pos_X_l      -0.061676\nWrist_Pos_Y_l      -0.213780\nWrist_Pos_Z_l      -0.166560\nYaw_l              -0.178615\nstate               0.000000\nName: state, dtype: float64"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "corr_matrix = train_merged.corr()\n",
    "corr_matrix['state'].sort_values()\n",
    "\n",
    "corr_matrix2 = test_merged.corr()\n",
    "corr_matrix2['state'].sort_values()\n",
    "\n",
    "corr_matrix2['state'] - corr_matrix['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this setup we can see that most of the features we got are very much relevant!\n",
    "\n",
    "sadly we can see that there is quite a difference between the test, and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframeToXY(df):\n",
    "    X = df.iloc[:,range(0,m - 1)].to_numpy()\n",
    "    y = df['state'].to_numpy()\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_full, y_train_unshuffled = dataframeToXY(train_merged)\n",
    "\n",
    "#print(X_train_full[::500][:5], y_train_unshuffled[::500][:5])\n",
    "#train_merged.iloc[::500][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, size = 0.8):\n",
    "    m = int(len(X) * size)\n",
    "    return (X[:m], y[:m], X[m:], y[m:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "shuffle_indecies = np.random.permutation(len(X_train_full))\n",
    "\n",
    "X_train_full_s = X_train_full[shuffle_indecies]\n",
    "y_train_full = y_train_unshuffled[shuffle_indecies]\n",
    "\n",
    "X_train, y_train, X_validate, y_validate = split(X_train_full[shuffle_indecies], y_train_unshuffled[shuffle_indecies], 0.8)\n",
    "\n",
    "X_test, y_test = dataframeToXY(test_merged)\n",
    "\n",
    "shuffle_indecies_t = np.random.permutation(len(X_test))\n",
    "X_test = X_test[shuffle_indecies_t]\n",
    "y_test = y_test[shuffle_indecies_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "19367 15493 3874 5680\n"
    }
   ],
   "source": [
    "print(len(X_train_full_s), len(X_train), len(X_validate), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[:5]\n",
    "#y_train[:5]\n",
    "#train_merged.iloc[shuffle_indecies][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice we've got a training set, validation set, and test set\n",
    "\n",
    "now we can test some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.925644083109756"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "log_reg = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.999)),\n",
    "    ('lin', LogisticRegression())\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression() having a score of 92% on cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.999)),\n                ('lin', LogisticRegression())])"
     },
     "metadata": {},
     "execution_count": 90
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9220443985544656"
     },
     "metadata": {},
     "execution_count": 90
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8985915492957747"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "log_reg.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "#log_reg.score(X_train, y_train)\n",
    "log_reg.score(X_validate, y_validate)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "almost 90% accuracity on the test set that's impresive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the SVC model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.999)),\n",
    "    ('svm', SVC(probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9941909247886249"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got a real good score with the svm model on the cross_validtion 98%!\n",
    "\n",
    "with suggest that the SVM model doing very well on the training set, and does not significantly overfitting,\n",
    "\n",
    "as it performs well on different folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.999)),\n                ('svm', SVC(probability=True))])"
     },
     "metadata": {},
     "execution_count": 93
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9967727360743561"
     },
     "metadata": {},
     "execution_count": 93
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9976768198244709"
     },
     "metadata": {},
     "execution_count": 93
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9373239436619718"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "svm_model.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "svm_model.score(X_train, y_train)\n",
    "svm_model.score(X_validate, y_validate)\n",
    "\n",
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get a score of 93.5%+ on the test set, that very good,\n",
    "\n",
    "but we have about 6% drop from the training set, with suggest the testing data is somehow different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8763967676530321"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tree = Pipeline([\n",
    "    #('PCA', PCA(0.99)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=4)),\n",
    "])\n",
    "\n",
    "svm_scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('tree', DecisionTreeClassifier(max_depth=4))])"
     },
     "metadata": {},
     "execution_count": 95
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8792357839024075"
     },
     "metadata": {},
     "execution_count": 95
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8673205988642231"
     },
     "metadata": {},
     "execution_count": 95
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7813380281690141"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)\n",
    "\n",
    "tree.score(X_train, y_train)\n",
    "tree.score(X_validate, y_validate)\n",
    "\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same stuff happens here the score for the training data is significantly better then,\n",
    "\n",
    "the score on the testing, again that support the idea that the testing data somehow different.\n",
    "\n",
    "now i will test many different models, and in the end i will try to use ensemble to boost our testing score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()), ('sgd_clf', SGDClassifier())])"
     },
     "metadata": {},
     "execution_count": 96
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9277232834279814"
     },
     "metadata": {},
     "execution_count": 96
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8852112676056338"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "sgd_clf = Pipeline([\n",
    "    #('PCA', PCA(0.99)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('sgd_clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "sgd_clf.score(X_validate, y_validate)\n",
    "sgd_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.99)),\n                ('forest',\n                 RandomForestClassifier(max_depth=5, max_leaf_nodes=55,\n                                        n_estimators=150, n_jobs=-1,\n                                        oob_score=True))])"
     },
     "metadata": {},
     "execution_count": 97
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9054577464788732"
     },
     "metadata": {},
     "execution_count": 97
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9340998397825491"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rnd_clf = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.99)),\n",
    "    (\"forest\" , RandomForestClassifier(max_depth=5, n_estimators=150, max_leaf_nodes=55, n_jobs=-1, oob_score=True))\n",
    "])\n",
    "cross_scores = cross_val_score(rnd_clf, X_train, y_train, cv=5)\n",
    "cross_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf.fit(X_train_full_s, y_train_full)\n",
    "rnd_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.99)),\n                ('gbrt',\n                 GradientBoostingClassifier(learning_rate=0.15, max_depth=4,\n                                            n_estimators=20, subsample=0.7))])"
     },
     "metadata": {},
     "execution_count": 98
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9063380281690141"
     },
     "metadata": {},
     "execution_count": 98
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9584408879710893"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.99)),\n",
    "    (\"gbrt\" ,  GradientBoostingClassifier(max_depth=4, n_estimators=20, learning_rate=0.15, subsample=0.7))\n",
    "])\n",
    "cross_scores = cross_val_score(gbrt, X_train, y_train, cv=5)\n",
    "cross_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt.fit(X_train_full_s, y_train_full)\n",
    "gbrt.score(X_test, y_test)\n",
    "gbrt.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('gbrt',\n                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n                                    learning_rate=0.11, n_estimators=10))])"
     },
     "metadata": {},
     "execution_count": 100
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8644366197183099"
     },
     "metadata": {},
     "execution_count": 100
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8789364997418688"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = Pipeline([\n",
    "    #('std_scaler', StandardScaler()),\n",
    "    #('pca', PCA(0.99)),\n",
    "    (\"gbrt\" ,  AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), n_estimators=10, learning_rate=0.11))\n",
    "])\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_clf.score(X_validate, y_validate)\n",
    "ada_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.999)), ('gnb', GaussianNB())])"
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8980382034073309"
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8697183098591549"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_gausiyan = Pipeline([\n",
    "    #('std_scaler', StandardScaler()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.999)),\n",
    "    (\"gnb\", GaussianNB()),\n",
    "])\n",
    "\n",
    "model_gausiyan.fit(X_train, y_train)\n",
    "model_gausiyan.score(X_validate, y_validate)\n",
    "model_gausiyan.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('pca', PCA(n_components=0.999)),\n                ('adag2',\n                 AdaBoostClassifier(base_estimator=VotingClassifier(estimators=[('gnb',\n                                                                                 GaussianNB()),\n                                                                                ('log_reg',\n                                                                                 LogisticRegression()),\n                                                                                ('tree',\n                                                                                 DecisionTreeClassifier(max_depth=3))],\n                                                                    voting='soft'),\n                                    learning_rate=0.2, n_estimators=15))])"
     },
     "metadata": {},
     "execution_count": 104
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9388756212483057"
     },
     "metadata": {},
     "execution_count": 104
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9370160041300981"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_g2 = AdaBoostClassifier(\n",
    "    VotingClassifier(estimators=[(\"gnb\", GaussianNB()), ('log_reg', LogisticRegression()), ('tree', DecisionTreeClassifier(max_depth=3))], voting='soft'), n_estimators= 15,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.2)\n",
    "model_super_complex = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('pca', PCA(0.999)),\n",
    "    ('adag2', ada_g2)\n",
    "    #(\"gnb\", GaussianNB()),\n",
    "])\n",
    "\n",
    "model_super_complex.fit(X_train, y_train)\n",
    "model_super_complex.score(X_train, y_train)\n",
    "model_super_complex.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.882218309859155"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "model_super_complex.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AdaBoostClassifier(base_estimator=VotingClassifier(estimators=[('gnb',\n                                                                GaussianNB()),\n                                                               ('log_reg',\n                                                                LogisticRegression()),\n                                                               ('tree',\n                                                                DecisionTreeClassifier(max_depth=3))],\n                                                   voting='soft'),\n                   learning_rate=0.2, n_estimators=20)"
     },
     "metadata": {},
     "execution_count": 106
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8907248434776996"
     },
     "metadata": {},
     "execution_count": 106
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8861641713990708"
     },
     "metadata": {},
     "execution_count": 106
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8698943661971831"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_g = AdaBoostClassifier(\n",
    "    VotingClassifier(estimators=[(\"gnb\", GaussianNB()), ('log_reg', LogisticRegression()), ('tree', DecisionTreeClassifier(max_depth=3))], voting='soft'), n_estimators= 20,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.2)\n",
    "ada_g.fit(X_train, y_train)\n",
    "ada_g.score(X_train, y_train)\n",
    "ada_g.score(X_validate, y_validate)\n",
    "ada_g.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VotingClassifier(estimators=[('log_reg',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('lin', LogisticRegression())])),\n                             ('svm',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('svm', SVC(probability=True))])),\n                             ('forest',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_compone...\n                              Pipeline(steps=[('gbrt',\n                                               AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n                                                                  learning_rate=0.11,\n                                                                  n_estimators=10))])),\n                             ('adaj',\n                              AdaBoostClassifier(base_estimator=VotingClassifier(estimators=[('gnb',\n                                                                                              GaussianNB()),\n                                                                                             ('log_reg',\n                                                                                              LogisticRegression()),\n                                                                                             ('tree',\n                                                                                              DecisionTreeClassifier(max_depth=3))],\n                                                                                 voting='soft'),\n                                                 learning_rate=0.2,\n                                                 n_estimators=20))],\n                 voting='soft')"
     },
     "metadata": {},
     "execution_count": 107
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9833473181436778"
     },
     "metadata": {},
     "execution_count": 107
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9819308208569953"
     },
     "metadata": {},
     "execution_count": 107
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9376760563380282"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('log_reg', log_reg), ('svm', svm_model),  (\"forest\", rnd_clf), (\"ada\", ada_clf), ('adaj', ada_g)], voting = \"soft\")\n",
    "\n",
    "voting_clf.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "voting_clf.score(X_train, y_train)\n",
    "voting_clf.score(X_validate, y_validate)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VotingClassifier(estimators=[('log_reg',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('lin', LogisticRegression())])),\n                             ('svm',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('svm', SVC(probability=True))])),\n                             ('adaboost',\n                              Pipeline(steps=[('gbrt',\n                                               AdaBoostClassifier(base_estimator=Decision...\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.99)),\n                                              ('forest',\n                                               RandomForestClassifier(max_depth=5,\n                                                                      max_leaf_nodes=55,\n                                                                      n_estimators=150,\n                                                                      n_jobs=-1,\n                                                                      oob_score=True))])),\n                             ('gbrt',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.99)),\n                                              ('gbrt',\n                                               GradientBoostingClassifier(learning_rate=0.15,\n                                                                          max_depth=4,\n                                                                          n_estimators=20,\n                                                                          subsample=0.7))]))],\n                 voting='soft')"
     },
     "metadata": {},
     "execution_count": 108
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9767636997353644"
     },
     "metadata": {},
     "execution_count": 108
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9731543624161074"
     },
     "metadata": {},
     "execution_count": 108
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9373239436619718"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('log_reg', log_reg), ('svm', svm_model), (\"adaboost\", ada_clf), (\"gaus\", model_gausiyan), \n",
    "        ('adaj', ada_g), (\"forest\", rnd_clf), (\"gbrt\", gbrt)], voting = \"soft\")\n",
    "\n",
    "voting_clf.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "voting_clf.score(X_train, y_train)\n",
    "voting_clf.score(X_validate, y_validate)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('log_reg', log_reg), ('svm', svm_model), ('svm2', svm_model), ('adaj2', ada_g2), ('adaj', ada_g) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VotingClassifier(estimators=[('log_reg',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('lin', LogisticRegression())])),\n                             ('svm',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('svm', SVC(probability=True))])),\n                             ('svm2',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_component...\n                                                                                              LogisticRegression()),\n                                                                                             ('tree',\n                                                                                              DecisionTreeClassifier(max_depth=3))],\n                                                                                 voting='soft'),\n                                                 learning_rate=0.2,\n                                                 n_estimators=15)),\n                             ('adaj',\n                              AdaBoostClassifier(base_estimator=VotingClassifier(estimators=[('gnb',\n                                                                                              GaussianNB()),\n                                                                                             ('log_reg',\n                                                                                              LogisticRegression()),\n                                                                                             ('tree',\n                                                                                              DecisionTreeClassifier(max_depth=3))],\n                                                                                 voting='soft'),\n                                                 learning_rate=0.2,\n                                                 n_estimators=20))],\n                 voting='soft')"
     },
     "metadata": {},
     "execution_count": 110
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9958691021751759"
     },
     "metadata": {},
     "execution_count": 110
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.996386164171399"
     },
     "metadata": {},
     "execution_count": 110
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9394366197183098"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "        estimators = models, voting = \"soft\")\n",
    "\n",
    "voting_clf.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "voting_clf.score(X_train, y_train)\n",
    "voting_clf.score(X_validate, y_validate)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VotingClassifier(estimators=[('log_reg',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('lin', LogisticRegression())])),\n                             ('svm',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('pca', PCA(n_components=0.999)),\n                                              ('svm', SVC(probability=True))])),\n                             ('adaboost',\n                              Pipeline(steps=[('gbrt',\n                                               AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n                                                                  learning_rate=0.11,\n                                                                  n_estimators=10))])),\n                             ('sgd',\n                              Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('sgd_clf', SGDClassifier())]))])"
     },
     "metadata": {},
     "execution_count": 111
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9472665074549796"
     },
     "metadata": {},
     "execution_count": 111
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9465668559628291"
     },
     "metadata": {},
     "execution_count": 111
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8966549295774648"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "        estimators = [('log_reg', log_reg), ('svm', svm_model), (\"adaboost\", ada_clf), (\"sgd\", sgd_clf) ], voting = \"hard\")\n",
    "\n",
    "voting_clf.fit(X_train_full_s, y_train_full)\n",
    "\n",
    "voting_clf.score(X_train, y_train)\n",
    "voting_clf.score(X_validate, y_validate)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(_arr):\n",
    "    m = len(_arr)\n",
    "    arr = np.array(_arr)\n",
    "    combs = []\n",
    "    for i in range(0,2**m):\n",
    "        pr = [bool(int(x)) for x in bin(i)[2:]]\n",
    "        for j in range(m - len(pr)):\n",
    "            pr.insert(0, False)\n",
    "        combination = arr[pr]\n",
    "        combs.append(combination)\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array([], dtype=int32),\n array([3]),\n array([2]),\n array([2, 3]),\n array([1]),\n array([1, 3]),\n array([1, 2]),\n array([1, 2, 3])]"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "combinations([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of trying every combination possible with voting classifier, we would just generate all the possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'log_reg' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-bba878bda449>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels_pr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_reg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'svm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_reg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'svm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m add_models = [(\"gbrt_add\", gbrt), (\"gaus_add\", model_gausiyan), ('svm_add', svm_model), (\"forest_add\", rnd_clf), \n\u001b[0;32m      4\u001b[0m     ('adaboost_mix', ada_g), ('adaboost_mix_pip', model_super_complex), (\"adaboost\", ada_clf)]\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_reg' is not defined"
     ]
    }
   ],
   "source": [
    "models_pr = [[('log_reg', log_reg)], [('svm', svm_model)], [('log_reg', log_reg), ('svm', svm_model)]]\n",
    "\n",
    "add_models = [(\"gbrt_add\", gbrt), (\"gaus_add\", model_gausiyan), ('svm_add', svm_model), (\"forest_add\", rnd_clf), \n",
    "    ('adaboost_mix', ada_g), ('adaboost_mix_pip', model_super_complex), (\"adaboost\", ada_clf)]\n",
    "\n",
    "best_estimators = []\n",
    "best_score = 0\n",
    "\n",
    "iteration  = 0\n",
    "for model in models_pr:\n",
    "    for combination in combinations(add_models):\n",
    "        iteration += 1\n",
    "        estimators = list(model) + list(combination)\n",
    "        test_model = VotingClassifier(estimators = estimators, voting = \"soft\", n_jobs = -1)\n",
    "        with io.capture_output() as captured:\n",
    "            test_model.fit(X_train_full_s, y_train_full)\n",
    "        score_test = test_model.score(X_test, y_test)\n",
    "        print(\"iteration : \", iteration, \" score : \", score_test)\n",
    "        if(score_test > best_score):\n",
    "            best_score = score_test\n",
    "            best_estimators = estimators\n",
    "print(\"--------------------------------\")\n",
    "best_score\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models_pr = [[('log_reg', log_reg)], [('svm', svm_model)], [('log_reg', log_reg), ('svm', svm_model)]]\n",
    "\n",
    "add_models = [(\"gbrt_add\", gbrt), (\"gaus_add\", model_gausiyan), ('log_reg_add', log_reg), ('svm_add', svm_model), ('tree', tree),\n",
    "     (\"forest_add\", rnd_clf), ('adaboost_mix', ada_g), ('adaboost_mix_pip', model_super_complex), (\"adaboost\", ada_clf)]\n",
    "\n",
    "best_estimators2 = []\n",
    "best_score2 = 0\n",
    "\n",
    "iteration  = 0\n",
    "for model in models_pr:\n",
    "    for combination in combinations(add_models):\n",
    "        iteration += 1\n",
    "        estimators = list(model) + list(combination)\n",
    "        test_model = VotingClassifier(estimators = estimators, voting = \"soft\", n_jobs = -1)\n",
    "        with io.capture_output() as captured:\n",
    "            test_model.fit(X_train, y_train)\n",
    "        score_test = test_model.score(X_validate, y_validate)\n",
    "        print(\"iteration : \", iteration, \" score : \", score_test)\n",
    "        if(score_test > best_score2):\n",
    "            best_score2 = score_test\n",
    "            best_estimators2 = estimators\n",
    "print(\"--------------------------------\")\n",
    "best_score2\n",
    "best_estimators2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'best_estimators' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-a4beacf0b91c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_estimators' is not defined"
     ]
    }
   ],
   "source": [
    "best_estimators"
   ]
  }
 ]
}